{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT8ZPNFISPOb",
        "outputId": "347ee9d8-47e4-4c04-f31c-ca30a29134b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: apache-tvm in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (23.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.11.4)\n",
            "Requirement already satisfied: synr==0.6.0 in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (0.6.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install apache-tvm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nO9Cic5HxnQK"
      },
      "outputs": [],
      "source": [
        "import tvm\n",
        "from tvm import te\n",
        "from tvm import autotvm\n",
        "import tvm.testing\n",
        "import numpy as np\n",
        "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
        "\n",
        "import logging\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "er5dPDdFzPci"
      },
      "outputs": [],
      "source": [
        "target = 'llvm'\n",
        "dev = tvm.cpu(0)\n",
        "dtype=\"float32\"\n",
        "M, N, K = 1024, 1024, 1024\n",
        "A_ = np.random.uniform(size=(N, K))\n",
        "B_ = np.random.uniform(size=(K, M))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RvwrAx01vLG",
        "outputId": "75e732ed-5240-44ef-c3a5-ab4673ad4cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], [])}\n",
            "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
            "  for (i.outer: int32, 0, 256) {\n",
            "    for (i.inner: int32, 0, 4) {\n",
            "      for (j.outer: int32, 0, 256) {\n",
            "        for (j.inner: int32, 0, 4) {\n",
            "          C_3: Buffer(C_2, float32, [1048576], [])[((((i.outer*4096) + (i.inner*1024)) + (j.outer*4)) + j.inner)] = 0f32\n",
            "          for (k: int32, 0, 1024) {\n",
            "            let cse_var_3: int32 = (j.outer*4)\n",
            "            let cse_var_2: int32 = ((i.outer*4096) + (i.inner*1024))\n",
            "            let cse_var_1: int32 = ((cse_var_2 + cse_var_3) + j.inner)\n",
            "            C_3[cse_var_1] = (C_3[cse_var_1] + (A_3: Buffer(A_2, float32, [1048576], [])[(cse_var_2 + k)]*B_3: Buffer(B_2, float32, [1048576], [])[(((k*1024) + cse_var_3) + j.inner)]))\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @autotvm.template(\"tvm_my_matmul\")\n",
        "def tvm_my_matmul_transform():\n",
        "    A = te.placeholder((M, K), name='A')\n",
        "    B = te.placeholder((K, N), name='B')\n",
        "\n",
        "    k = te.reduce_axis((0, K), name='k')\n",
        "    C = te.compute((M, N),\n",
        "                    lambda i, j: te.sum(\n",
        "                        A[i, k] * B[k, j], axis=k\n",
        "                        ), name='C')\n",
        "\n",
        "    s = te.create_schedule(C.op)\n",
        "\n",
        "    i, j = C.op.axis\n",
        "    io, ii = s[C].split(i, factor=4)\n",
        "    jo, ji = s[C].split(j, factor=4)\n",
        "    return s, [A, B, C]\n",
        "\n",
        "s, (A, B, C) = tvm_my_matmul_transform()\n",
        "print(tvm.lower(s, [A, B, C], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wfyWA9UJ79a8"
      },
      "outputs": [],
      "source": [
        "def run_tuning(tasks, measure_option, tuner=\"gridsearch\", early_stopping=None,\n",
        "               log_filename=\"tuning.log\", n_trial=None):\n",
        "    for i, task in enumerate(tasks):\n",
        "        prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
        "\n",
        "        # create tuner\n",
        "        if tuner == \"xgb\" or tuner == \"xgb-rank\":\n",
        "            tuner_obj = XGBTuner(task, loss_type=\"rank\")\n",
        "        elif tuner == \"ga\":\n",
        "            tuner_obj = GATuner(task, pop_size=50)\n",
        "        elif tuner == \"random\":\n",
        "            tuner_obj = RandomTuner(task)\n",
        "        elif tuner == \"gridsearch\":\n",
        "            tuner_obj = GridSearchTuner(task)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid tuner: \" + tuner)\n",
        "\n",
        "        # do tuning\n",
        "        n_trial = min(n_trial or len(task.config_space), len(task.config_space))\n",
        "        tuner_obj.tune(\n",
        "            n_trial=n_trial or len(task.config_space),\n",
        "            early_stopping=early_stopping,\n",
        "            measure_option=measure_option,\n",
        "            callbacks=[\n",
        "                autotvm.callback.progress_bar(n_trial, prefix=prefix),\n",
        "                autotvm.callback.log_to_file(log_filename),\n",
        "            ],\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XoxZ_PGnWIjf"
      },
      "outputs": [],
      "source": [
        "logging.getLogger(\"autotvm\").setLevel(logging.DEBUG)\n",
        "logging.getLogger(\"autotvm\").addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "log_file = \"tune.log\"\n",
        "tuning_option = {\n",
        "    \"log_filename\": log_file,\n",
        "    \"n_trial\": 10,\n",
        "    \"tuner\": \"xgb\",\n",
        "    \"early_stopping\": None,\n",
        "    \"measure_option\": autotvm.measure_option(\n",
        "        builder='local',\n",
        "        runner=autotvm.LocalRunner(\n",
        "            number=5, repeat=2, min_repeat_ms=0, enable_cpu_cache_flush=True\n",
        "        ),\n",
        "    ),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JEIELPZSTUQm"
      },
      "outputs": [],
      "source": [
        "@autotvm.template(\"my_matmul_template\")\n",
        "def tvm_my_matmul_template(M, N, K, dtype):\n",
        "    A = te.placeholder((M, K), name='A', dtype=dtype)\n",
        "    B = te.placeholder((K, N), name='B', dtype=dtype)\n",
        "\n",
        "    k = te.reduce_axis((0, K), name='k')\n",
        "    C = te.compute((M, N),\n",
        "                    lambda i, j: te.sum(\n",
        "                        A[i, k] * B[k, j], axis=k\n",
        "                        ), name='C')\n",
        "\n",
        "    s = te.create_schedule(C.op)\n",
        "\n",
        "    i, j = s[C].op.axis\n",
        "    k = s[C].op.reduce_axis[0]\n",
        "\n",
        "    candidates = [[1, 1024], [2, 512], [4, 256], [8, 128], [16, 64], [32, 32], [64, 16], [128, 8], [256, 4], [512, 2], [1024, 1]]\n",
        "\n",
        "    cfg = autotvm.get_config()\n",
        "    cfg.define_split(\"tile_y\", i, num_outputs=2, policy=\"candidate\", candidate=candidates)\n",
        "    cfg.define_split(\"tile_x\", j, num_outputs=2, policy=\"candidate\", candidate=candidates)\n",
        "\n",
        "    yo, yi = cfg[\"tile_y\"].apply(s, C, i)\n",
        "    xo, xi = cfg[\"tile_x\"].apply(s, C, j)\n",
        "\n",
        "    s[C].reorder(yo, xo, k, yi, xi)\n",
        "\n",
        "    return s, [A, B, C]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ivtVt5oHnf",
        "outputId": "4d835b46-79c9-42b0-b138-1c6b87795ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Byte Order:                         Little Endian\n",
            "L1d cache:                          32 KiB (1 instance)\n",
            "L1i cache:                          32 KiB (1 instance)\n",
            "L2 cache:                           256 KiB (1 instance)\n",
            "L3 cache:                           55 MiB (1 instance)\n",
            "Vulnerability L1tf:                 Mitigation; PTE Inversion\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e1pJCyNVj865"
      },
      "outputs": [],
      "source": [
        "def filter(e):\n",
        "    max_bx = e[\"tile_x\"].size[0] <= e[\"tile_x\"].size[1]\n",
        "    inline_cache = e[\"tile_y\"].size[1] <= e[\"tile_x\"].size[1]\n",
        "    cache_kbytes = 32\n",
        "    constrains = 4 * (e[\"tile_x\"].size[1] + e[\"tile_y\"].size[1] + e[\"tile_x\"].size[1] * e[\"tile_y\"].size[1]) <= cache_kbytes * 1024\n",
        "    return max_bx and constrains and inline_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sNnr_yullxV0"
      },
      "outputs": [],
      "source": [
        "@autotvm.template(\"filtered_c_template\")\n",
        "def filtered_c_template(M, N, K, dtype):\n",
        "    A = te.placeholder((M, K), name='A', dtype=dtype)\n",
        "    B = te.placeholder((K, N), name='B', dtype=dtype)\n",
        "\n",
        "    k = te.reduce_axis((0, K), name='k')\n",
        "    C = te.compute((M, N),\n",
        "                    lambda i, j: te.sum(\n",
        "                        A[i, k] * B[k, j], axis=k\n",
        "                        ), name='C')\n",
        "\n",
        "    s = te.create_schedule(C.op)\n",
        "\n",
        "    i, j = s[C].op.axis\n",
        "    k = s[C].op.reduce_axis[0]\n",
        "\n",
        "    candidates = [[1, 1024], [2, 512], [4, 256], [8, 128], [16, 64], [32, 32], [64, 16], [128, 8], [256, 4], [512, 2], [1024, 1]]\n",
        "\n",
        "    cfg = autotvm.get_config()\n",
        "    cfg.multi_filter(filter=filter)\n",
        "    cfg.define_split(\"tile_y\", i, num_outputs=2, policy=\"candidate\", candidate=candidates)\n",
        "    cfg.define_split(\"tile_x\", j, num_outputs=2, policy=\"candidate\", candidate=candidates)\n",
        "\n",
        "    yo, yi = cfg[\"tile_y\"].apply(s, C, i)\n",
        "    xo, xi = cfg[\"tile_x\"].apply(s, C, j)\n",
        "\n",
        "    s[C].reorder(yo, xo, k, yi, xi)\n",
        "\n",
        "    return s, [A, B, C]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC6n7QjGlvMG",
        "outputId": "caaff25e-7187-4d0a-ab4c-8f65b2e87af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConfigSpace (len=121, range_length=121, space_map=\n",
            "   0 tile_y: Split(policy=candidate, product=1024, num_outputs=2) len=11\n",
            "   1 tile_x: Split(policy=candidate, product=1024, num_outputs=2) len=11\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "task1 = autotvm.task.create(\"my_matmul_template\", args=(M, N, K, dtype), target=target)\n",
        "print(task1.config_space)\n",
        "# for idx in range(task1.config_space.range_length):\n",
        "#     if task1.config_space.is_index_valid(idx):\n",
        "#         print(task1.config_space.get(idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2WlcmKSl857",
        "outputId": "18ceb219-130c-4b86-f6f8-dc235e904f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConfigSpace (len=33, range_length=121, space_map=\n",
            "   0 tile_y: Split(policy=candidate, product=1024, num_outputs=2) len=11\n",
            "   1 tile_x: Split(policy=candidate, product=1024, num_outputs=2) len=11\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "task2 = autotvm.task.create(\"filtered_c_template\", args=(M, N, K, dtype), target=target)\n",
        "print(task2.config_space)\n",
        "# for idx in range(task2.config_space.range_length):\n",
        "#     if task2.config_space.is_index_valid(idx):\n",
        "#         print(task2.config_space.get(idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMJyiJp5WNmY"
      },
      "outputs": [],
      "source": [
        "tasks = [task1, task2]\n",
        "run_tuning(tasks, **tuning_option)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9bSKQJIj_S6",
        "outputId": "225007c9-aeb4-4a0e-b27c-1b3e538fd428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_matmul_template [(2.9015676975250244, [['tile_y', 'sp', [128, 8]], ['tile_x', 'sp', [2, 512]]]), (3.1571240425109863, [['tile_y', 'sp', [8, 128]], ['tile_x', 'sp', [1, 1024]]])]\n",
            "filtered_c_template [(2.9636354446411133, [['tile_y', 'sp', [1024, 1]], ['tile_x', 'sp', [1, 1024]]]), (3.156834125518799, [['tile_y', 'sp', [512, 2]], ['tile_x', 'sp', [4, 256]]])]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import json\n",
        "results = defaultdict(list)\n",
        "with open(log_file, 'r') as f:\n",
        "    data = f.read()\n",
        "    data = data.split('\\n')\n",
        "    for d in data:\n",
        "        if not d:\n",
        "            continue\n",
        "        d = json.loads(d)\n",
        "        name = d['input'][1]\n",
        "        sz = d['config']['entity']\n",
        "        res = d['result']\n",
        "        res_v = res[-2]\n",
        "        res_e = res[-3]\n",
        "        if res_e == 0:\n",
        "            results[name].append((res_v, sz))\n",
        "\n",
        "\n",
        "for name, res in results.items():\n",
        "    print(name, sorted(res, key=lambda x: x[0])[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zOCsBqrCWuZJ"
      },
      "outputs": [],
      "source": [
        "dev = tvm.cpu(0)\n",
        "a = np.random.uniform(size=(M, K)).astype(dtype)\n",
        "b = np.random.uniform(size=(K, N)).astype(dtype)\n",
        "c_tvm = tvm.nd.array(np.zeros((M, N), dtype=dtype), dev)\n",
        "c_np = np.matmul(a, b)\n",
        "a = tvm.nd.array(a)\n",
        "b = tvm.nd.array(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zl2UnbOWlhb",
        "outputId": "1aed34e8-9b52-4a6a-e5c4-ac687a007f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finish loading 20 records\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:autotvm:Finish loading 20 records\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], [])}\n",
            "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
            "  for (i.outer: int32, 0, 128) {\n",
            "    for (j.outer: int32, 0, 2) {\n",
            "      for (i.inner.init: int32, 0, 8) {\n",
            "        for (j.inner.init: int32, 0, 512) {\n",
            "          C_3: Buffer(C_2, float32, [1048576], [])[((((i.outer*8192) + (i.inner.init*1024)) + (j.outer*512)) + j.inner.init)] = 0f32\n",
            "        }\n",
            "      }\n",
            "      for (k: int32, 0, 1024) {\n",
            "        for (i.inner: int32, 0, 8) {\n",
            "          for (j.inner: int32, 0, 512) {\n",
            "            let cse_var_3: int32 = (j.outer*512)\n",
            "            let cse_var_2: int32 = ((i.outer*8192) + (i.inner*1024))\n",
            "            let cse_var_1: int32 = ((cse_var_2 + cse_var_3) + j.inner)\n",
            "            C_3[cse_var_1] = (C_3[cse_var_1] + (A_3: Buffer(A_2, float32, [1048576], [])[(cse_var_2 + k)]*B_3: Buffer(B_2, float32, [1048576], [])[(((k*1024) + cse_var_3) + j.inner)]))\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "func 297.2796133\n"
          ]
        }
      ],
      "source": [
        "with autotvm.apply_history_best(log_file):\n",
        "    with tvm.target.Target(target):\n",
        "        s, (A, B, C) = tvm_my_matmul_template(M, N, K, dtype)\n",
        "        func = tvm.build(s, [A, B, C])\n",
        "        print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
        "\n",
        "        func(a, b, c_tvm)\n",
        "        tvm.testing.assert_allclose(c_np, c_tvm.numpy(), rtol=1e-4)\n",
        "\n",
        "        time_f = func.time_evaluator(func.entry_name, dev, number=10)\n",
        "        cost = time_f(a,b,c_tvm).mean\n",
        "        print(\"func\", cost*1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibS_p3SUqP0-",
        "outputId": "a518e7f1-2e40-47d8-c4a4-b3303c4aaad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finish loading 20 records\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:autotvm:Finish loading 20 records\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@main = primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], []),\n",
            "             C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], [])}\n",
            "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
            "  for (i.outer: int32, 0, 1024) {\n",
            "    for (j.inner.init: int32, 0, 1024) {\n",
            "      C_3: Buffer(C_2, float32, [1048576], [])[((i.outer*1024) + j.inner.init)] = 0f32\n",
            "    }\n",
            "    for (k: int32, 0, 1024) {\n",
            "      for (j.inner: int32, 0, 1024) {\n",
            "        let cse_var_2: int32 = (i.outer*1024)\n",
            "        let cse_var_1: int32 = (cse_var_2 + j.inner)\n",
            "        C_3[cse_var_1] = (C_3[cse_var_1] + (A_3: Buffer(A_2, float32, [1048576], [])[(cse_var_2 + k)]*B_3: Buffer(B_2, float32, [1048576], [])[((k*1024) + j.inner)]))\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "func 245.2255676\n"
          ]
        }
      ],
      "source": [
        "with autotvm.apply_history_best(log_file):\n",
        "    with tvm.target.Target(target):\n",
        "        s, (A, B, C) = filtered_c_template(M, N, K, dtype)\n",
        "        func = tvm.build(s, [A, B, C])\n",
        "        print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
        "\n",
        "        func(a, b, c_tvm)\n",
        "        tvm.testing.assert_allclose(c_np, c_tvm.numpy(), rtol=1e-4)\n",
        "\n",
        "        time_f = func.time_evaluator(func.entry_name, dev, number=10)\n",
        "        cost = time_f(a,b,c_tvm).mean\n",
        "        print(\"func\", cost*1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Io, Ii - e[\"tile_y\"].size[0], e[\"tile_y\"].size[1]\n",
        "\n",
        "Jo, Ji - e[\"tile_x\"].size[0], e[\"tile_x\"].size[1]\n",
        "\n",
        "- Базовый оптимизация - увеличение размеров блоков, т.е Ji и Ii должны быть больше, чем обратные им Jo и Io соответственно. (Io <= Ii, Jo <= Ji)\n",
        "- Причем желательно, чтобы Ji >= Ii, т.к это длина последовательных элементов в памяти и к ним обращение будет оптимальнее.\n",
        "- Для ограничения размеров блоков сверху выберем одну итерацию k, мы хотим чтобы блоки матриц A, B, C, с которыми мы работаем на этой итерации содержались в кеше. Их размеры соответственно: Ii, Ji, Ii*Ji. Т.к кеш у этой машины 32 килобайта, и мы работаем c float32 (4 байта), то получается соотношение 4 * (Ii + Ji + Ii*Ji) <= 32 * 1024\n",
        "- Чтобы сильно не сужать пространство поиска уберем не самое важное условие Io <= Ii\n",
        "\n",
        "При проведении исследований в таргет не включались векторные расширения AVX для чистоты экспериментов"
      ],
      "metadata": {
        "id": "GZfVre7r-vFF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMtIhsAedI/kJ5Jr1Ejs6aX"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
